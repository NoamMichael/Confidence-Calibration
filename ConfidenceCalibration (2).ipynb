{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc100733-981b-45df-9880-8d093ae2de24",
   "metadata": {},
   "source": [
    "## Confidence Calibration of Large Language Models\n",
    "Noam Michael<br>\n",
    "Advised by Dr. Jacob Bien<BR>\n",
    "USC Marshall School of Business, Data Science and Operations\n",
    "\n",
    "Contact: <br>\n",
    "nm_573@usc.edu<br>\n",
    "noammichael1163@gmail.com\n",
    "\n",
    "A very special thank you to Farhad De Sousa, Luis Bravo, the faculty and staff of the Department of Data Sciences and Operations, and the Center for Advanced Research in Computing for their incredible support throughout this project.\n",
    "\n",
    "Contact: <br>\n",
    "nm_573@usc.edu<br>\n",
    "noammichael1163@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791455ab-3cb1-4a23-8dc3-0c7fc62859da",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "As Large Language Models (LLMs) have gotten more popular, their tendency to create new facts has become a growing issue. This tendency for models to \"hallucinate\" ideas makes their output less reliable which, in turn, makes users less likely to trust the model and continue to use them in the future. One way to combat this is by having models output a \"confidence score\" which tells the user how confident the model is of its answer. The hope in this is that users know when to trust a models output and when to seek other sources. \n",
    "Over the course of this project, we want to investigate if the LLM's are able to self assess their understanding and accurately output a confidence score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02594ae9-921b-4cf3-a88a-9c6b78e14a86",
   "metadata": {},
   "source": [
    "### Examples of Hallucination:\n",
    "\n",
    "* Lawyers submitted bogus case law created by ChatGPT. A judge fined them $5,000:<BR>\n",
    "  https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c\n",
    "\n",
    "* ChatGPT makes nonsense diagnosis, cites fake papers:<BR>\n",
    "  https://www.nature.com/articles/s41537-023-00379-4\n",
    "\n",
    "* Google’s AI Recommended Adding Glue To Pizza:<BR>\n",
    "  https://www.forbes.com/sites/jackkelly/2024/05/31/google-ai-glue-to-pizza-viral-blunders/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960adefb-2e5a-4feb-bdb8-bfb6a32fbe71",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "#### Model and Dataset:\n",
    "For the sake of reproducibility, we used an open source dataset as well as strict controls over contributing factors. Over the course of this project, we ran in the same enviorment and eliminated randomness caused by variables like \"temperature\" and had the model sample using \"Greedy Decoding\" where it chose the token with the highest logit value\n",
    "\n",
    "We used Llama 3-8B, an open source LLM published by Meta. We also used BoolQ, an open source question answering dataset published by University of Washington and Google AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3440f-a0da-4f40-a199-209b93691ac4",
   "metadata": {},
   "source": [
    "##### Links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddb03b-c595-46ae-9094-61cf89bdcfa4",
   "metadata": {},
   "source": [
    "###### Llama 3 Download: \n",
    "https://huggingface.co/meta-llama/Meta-Llama-3-8B\n",
    "\n",
    "###### Llama 3 Info: \n",
    "https://ai.meta.com/blog/meta-llama-3/\n",
    "\n",
    "###### BoolQ Dataset: \n",
    "https://github.com/google-research-datasets/boolean-questions?tab=readme-ov-file\n",
    "\n",
    "###### Boolq Paper: \n",
    "https://arxiv.org/pdf/1905.10044"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb6e2a-375b-4bb8-afd7-14824cf0dd9a",
   "metadata": {},
   "source": [
    "#### Llama 3:\n",
    "\n",
    "Llama 3 is a Large Language Model trained to simulate conversation between an Assistant and User. We can provide Llama with a system prompt to define it's goals and specify how we want it's output to look like. Following the system prompt, we can provide it with a passage and corresponding question from our BoolQ dataset. \n",
    "\n",
    "*Example System Prompt: (From Meta)*\n",
    "\n",
    "><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    ">\n",
    ">You are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    ">\n",
    ">What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f685a-822c-4a3e-9d31-6388e5074d02",
   "metadata": {},
   "source": [
    "##### Note: The odd formating is how we communicate directions to the model. See explanation below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d722b26-39ad-4b90-beaa-cd9ab771d2b5",
   "metadata": {},
   "source": [
    "\n",
    ">**<|begin_of_text|>:** Specifies the start of the prompt <br>\n",
    ">\n",
    ">**<|start_header_id|>system<|end_header_id|>:** Specifies the role for the following message, i.e. “system”<br>\n",
    ">\n",
    ">**You are a helpful AI assistant for travel tips and recommendations:** The system prompt<br>\n",
    ">\n",
    ">**<|eot_id|>:** Specifies the end of the input message<br>\n",
    ">\n",
    ">**<|start_header_id|>user<|end_header_id|>:** Specifies the role for the following message i.e. “user”<br>\n",
    ">\n",
    ">**What can you help me with?:** The user message<br>\n",
    ">\n",
    ">**<|start_header_id|>assistant<|end_header_id|>:** Ends with the assistant header, to prompt the model to start generation.<br>\n",
    "\n",
    "More documentation on this can be found here : https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5468-81f9-46fa-9018-3b57674ff785",
   "metadata": {},
   "source": [
    "#### BoolQ Dataset: \n",
    "\n",
    "The BoolQ dataset is designed to train and test large language model. It is comprised of two JSONL files with several thousand examples.<br> The files are:\n",
    "\n",
    "**train.jsonl**: 9427 labeled training examples<br>\n",
    "**dev.jsonl**: 3270 labeled development examples<br>\n",
    "\n",
    "Both files are formatted similarly with a question, a title, an answer, and a correponding passage. For example, Question #8 in the dev.jsonl file:\n",
    "\n",
    "| Question | Title | Answer | Passage |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Can an odd number be divided by an even number? | Parity (mathematics) | True | In mathematics, parity is the property of an integer's inclusion in one of two categories: even or odd. An integer is even if it is evenly divisible by two and odd if it is not even. For example, 6 is even because there is no remainder when dividing it by 2. By contrast, 3, 5, 7, 21 leave a remainder of 1 when divided by 2. Examples of even numbers include −4, 0, 82 and 178. In particular, zero is an even number. Some examples of odd numbers are −5, 3, 29, and 73.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d887d2-6473-41ed-9736-e553d8fd6e42",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d2a95-b892-4049-a074-aeab9257e753",
   "metadata": {},
   "source": [
    "#### Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4c5e9-86fd-4c78-ae07-4cc5e3287b47",
   "metadata": {},
   "source": [
    "Throughout this project, we attmpted both probabilistic confidence scores as well as stated confidence scores. We based both of these methods off of prior conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42177c8-e0d1-4a4a-9bd1-f1c8b246b5a0",
   "metadata": {},
   "source": [
    "##### Probabilistic Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d95ea-7473-455b-a230-a9d3938777ec",
   "metadata": {},
   "source": [
    "We based the probabilistic confidence score off of the same logic as the Probability of Precipitation (PoP) used by the National Weather Service. This is a probability where a given score indicates the liklihood that something will happen. In our case, our model should be correct 80% of the times it states it is 80% confident if it is perfectly calibrated.\n",
    "\n",
    "An example output would look like:<BR>\n",
    "**Assistant: Yes, 90%**\n",
    "\n",
    "More info on PoP:<br>\n",
    "https://www.weather.gov/media/pah/WeatherEducation/pop.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7d86c-297c-4a7f-9863-a83dea5b7503",
   "metadata": {},
   "source": [
    "##### Stated Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b88dc7-29ea-49df-8310-dfcdbfad5d1c",
   "metadata": {},
   "source": [
    "Later in our research, we wanted to see if a stated confidence score would lead to better results. The motivation behind this was that the model may naturally have a better understanding of a stated word over a numerical score. We borrowed the idea of Words of Estimative Probabilities or WEPs from the intelligence community.\n",
    "\n",
    "| Very Uncertain | Somewhat Uncertain | Moderately Certain | Fairly Certain | Very Certain |\n",
    "|-|-|-|-|-|\n",
    "| 53% | 65% | 75% | 87.5% | 96.5% |\n",
    "\n",
    "**We split our confidence levels into  the top 3 categories used by the CIA:**\n",
    "\n",
    "\"chances about even\" = 50% <br>\n",
    " \n",
    "\"probable\" = 75%<BR>\n",
    "\n",
    "\"almost certain\" = 93%<BR>\n",
    "\n",
    "\n",
    "\n",
    "For more documentation on the CIA's Words of Estimative Probabilities, see:\n",
    "https://www.cia.gov/resources/csi/static/Words-of-Estimative-Probability.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0fe10-593a-4ada-bb6d-2df6900edfa7",
   "metadata": {},
   "source": [
    "#### Perfect Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0490c-8772-4647-985c-2b899b22aa17",
   "metadata": {},
   "source": [
    "As mentioned before, we define a model to be considered perfectly calibrated if for a given confidence value $X$ it is accurate $X$% of the time. \n",
    "<span style=\"font-size: 1.25em;\"><BR>\n",
    "Given,<BR>\n",
    "$(X,Y)$<BR>\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "Where<BR>\n",
    "$$ Y = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & \\mbox{if Answer is correct}  \\\\\n",
    "      0 & \\mbox{if Answer is wrong} \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "and, <BR>\n",
    "\n",
    "$ X = $ stated confidence $ \\in [0,1]$<BR>\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "Then,<BR>\n",
    "$\\mathbb{P}(Y = 1 | X = x) = X \\;\\;\\forall x \\in [0,1]$\n",
    "\n",
    "\n",
    "\n",
    "Note: This is our definition of *perfect* calibration. As you will see, the Llama is anything but."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ceeee-0186-44a5-a8bb-48f529ae9a7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### other version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ae090-facb-481e-9a83-6ef4b6d6a025",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$ \\forall  i \\in Q, A = X $\n",
    "\n",
    "Where,\n",
    "\n",
    "- $Q = \\{i| c_i = X\\}$\n",
    "\n",
    "- $c_i =$ Stated confidence for $i^{th}$ question\n",
    "\n",
    "- $X =$ Given confidence value\n",
    "\n",
    "- $A = \\frac{\\sum a_i} {|Q|}$\n",
    "\n",
    "- $a_i =$ Score for the $i^{th}$ question (1 or 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce17dc6f-e6a4-40fd-87c0-56e65a3de1bd",
   "metadata": {},
   "source": [
    "#### Measuring Error: The Brier Score\n",
    "\n",
    "We cannot expect our model to be perfectly calibrated at all times. Because of this we need a way to measure how close it is to perfect. For this, we looked to use the Brier score to quantify how close our model was to being perfect for a given run. The Brier score is essentially a Mean Squared Error that is adapted for boolean values (1 or 0). It is defined as:\n",
    "\n",
    "\n",
    "Population Brier Score:\n",
    "\n",
    "$B_p =\\mathbb{E} ( (Y - X)^2)$\n",
    "\n",
    "Sample Brier Score:\n",
    "\n",
    "$B_s = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - x_i)^2$\n",
    "\n",
    "Where,\n",
    "\n",
    "- $ N $ is the number of predictions\n",
    "- $ x_i $ is the predicted probability for the i-th instance\n",
    "- $ y_i $ is the actual outcome for the $i^{th}$ instance (1 if the answer was correct, 0 if it was not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e434591-4bdb-41dd-8b2c-b89f6f415ec4",
   "metadata": {},
   "source": [
    "##### Example of a Brier Score:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57d906-5902-4a21-a86b-77839d886aca",
   "metadata": {},
   "source": [
    "Lets say we are given this dataset:\n",
    "\n",
    "| Question    | Score | Confidence  |\n",
    "| -------- | ------- | ------- |\n",
    "| 1  | 1 | 90%    |\n",
    "| 2 | 0 | 50%     |\n",
    "| 3     | 1 |  75%   |\n",
    "\n",
    "\n",
    "Then our values would be:\n",
    "\n",
    "\n",
    "$N = 3$\n",
    "\n",
    "$x_1 = 1$ <BR>\n",
    "$x_2 = 0$ <BR>\n",
    "$x_3 = 1$<BR>\n",
    "\n",
    "$y_1 = 0.9$ <BR>\n",
    "$y_2 = 0.5$ <BR>\n",
    "$y_3 = 0.75$<BR>\n",
    "\n",
    "Then our sample Briar Score would be:\n",
    "\n",
    "$B_s = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - x_i)^2 $<BR><BR>\n",
    "$= \\frac{(0.9 - 1)^2 + (0.5 - 0)^2 + (0.75 - 1)^2}{3} $<BR><BR>\n",
    "$= \\frac{(-0.1)^2 + (0.5)^2 + (-0.25)^2}{3} $<BR><BR>\n",
    "$= \\frac{ 0.01 + 0.25 + 0.0625}{3}$ <BR><BR>\n",
    "$= \\frac{0.3225}{3}$<BR><BR>\n",
    "$= 0.1075$\n",
    "\n",
    "Note that a lower score is better as this is the *error* of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49038886-562d-45b5-b94a-c4c8e8b42af5",
   "metadata": {},
   "source": [
    "#### Logit-Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c789d3a-5dc2-44c7-b5d5-aebd6cbe69ea",
   "metadata": {},
   "source": [
    "When the model is given an input, it runs that input through several layers and outputs a list of *logits*. These are unormallized outputs assigned to each *token*. We then can run these logits through the *softmax* function to normalize these logit scores into a probability from 0-100% with the sum of all ptobabilities equalling 100%. These probabalities are based on how likely the model believes the token is to be the next word. \n",
    "\n",
    "For Example, a model may only have three tokens: \"Yes\", \"No\", and \"Maybe\". Then a conversation may look like this:\n",
    "\n",
    "**User**: Does it tend to rain in the fall?\n",
    "\n",
    "Based on this question, the model may create this table of values:\n",
    "\n",
    "| Token | Logit | Probability |\n",
    "|-------|-------|-------------|\n",
    "| Yes   | 8 | 87.6% |\n",
    "| Maybe | 6 | 11.8% |\n",
    "| No | 3 | 0.6% |\n",
    "\n",
    "As \"Yes\" is the token with the highest probability, the model would output:\n",
    "\n",
    "**Assistant**: Yes\n",
    "\n",
    "This table is usually not shown to the user however in our case it was useful to examine. Although inherently different from the confidence score discussed earlier, these \"Logit-Probability\" scores can give us insight into the models thinking. Because of this it is helpful to also examine these scores. In our data collection, we chose to omit the Logit scores and only show the normalized probability as they were not pertinent to what we were investigating. \n",
    "\n",
    "To get a value for a probability score for a given output we take the probability of the answered token and divide it by the sum of the probabilities of the 'Yes' and 'No' tokens. \n",
    "\n",
    "In our example:<BR><BR>\n",
    "<span style=\"font-size: 1.25em;\">\n",
    "$P_{answer} = \\frac{P_{yes}}{P_{yes} + P_{no}} $ <BR><BR>\n",
    "$= \\frac{0.876}{0.876 + 0.006}$ <BR><BR>\n",
    "$= \\frac{0.876}{0.882} = 0.993$ <BR>\n",
    "\n",
    "\n",
    "See below for a more in depth explanation of *Tokens* and  the *Softmax Function*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d70a99-5350-4916-a30e-c5de8c872204",
   "metadata": {},
   "source": [
    "##### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc212c-654e-47a2-b059-b01f17f4c106",
   "metadata": {},
   "source": [
    "Tokens are words or word fragments that the model has been pretrained to have embeddings for. These embeddings are high-dimensional vectors that help the model gain a sense of word association.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.\"<BR>\n",
    "-(Attention Is All You Need, Vaswani et al.)<BR>\n",
    "https://arxiv.org/abs/1706.03762\n",
    "\n",
    "Tokenization:\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\"> The <span style=\"color: blue;\"> dom<span style=\"color: green;\">inant <span style=\"color: orange;\">seq<span style=\"color: blue;\">uence <span style=\"color: red;\">trans<span style=\"color: purple;\">duc<span style=\"color: orange;\">tion <span style=\"color: blue;\">model<span style=\"color: orange;\">s <span style=\"color: green;\">are <span style=\"color: red;\">base<span style=\"color: blue;\">d <span style=\"color: orange;\">on <span style=\"color: black;\">...\n",
    "\n",
    "Notice how at times the token includes the entire word and at times it is only a word fragment. Different models and tokenizers can be trained to split words differently with some tokenizers even assigning multiple words to one token.\n",
    "\n",
    "\n",
    "For more see Grant Sanderson's video on this:\n",
    "\n",
    "https://youtu.be/wjZofJX0v4M?si=HeZizJeOrIBvCPko&t=748\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def63ea1-d6e2-41b9-b558-200d3698242f",
   "metadata": {},
   "source": [
    "##### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d417644-547c-497d-910c-2d7abd47d246",
   "metadata": {},
   "source": [
    "The Softmax function is defined as:<BR>\n",
    "<span style=\"font-size: 2em;\">\n",
    "$\\sigma (z_i) = \\frac{  e^{z_i} }{\\sum_{j=1}^n e^{z_j}}$<BR>\n",
    "<span style=\"font-size: 0.5em;\">\n",
    "Given logit vector $z = [8, 6, 3] $ from our example:<BR>\n",
    "<span style=\"font-size: 1.5em;\">\n",
    "$\\sum_{j=1}^n e^{z_j} = e^8 + e^6 + e^3 = 3404$<BR>\n",
    "\n",
    "Thus,<BR>\n",
    "<span style=\"font-size: 1.5em;\">\n",
    "$\\sigma (z_1) = \\sigma (8) = \\frac{  e^{8} }{\\sum_{j=1}^n e^{z_j}} = \\frac{2980}{3404} = 0.875$<BR><BR>\n",
    "<span style=\"font-size: 1em;\">\n",
    "$\\sigma (z_2) = \\sigma (6) =\\frac{  e^{6} }{\\sum_{j=1}^n e^{z_j}} = \\frac{403}{3404} = 0.118$<BR><BR>\n",
    "<span style=\"font-size: 1em;\">\n",
    "$\\sigma (z_3) = \\sigma (3) =\\frac{  e^{3} }{\\sum_{j=1}^n e^{z_j}} = \\frac{20}{3404} = 0.006$<BR><BR>\n",
    "\n",
    "\n",
    "For simplicity, we rounded to whole numbers in the intermediate step.\n",
    "\n",
    "For more see Grant Sanderson's video on this and how *temperature* can impact output:\n",
    "\n",
    "https://youtu.be/wjZofJX0v4M?si=8Ex7TbUwsJBtVIrG&t=1342"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be02c6d0-0d86-4bcb-bc69-12342e38b655",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "This notebook is based off a tutorial on how to use LLaMA 3 from the hugging face library. As a note, this notebook will not work unless you get a private access key from Meta/ Hugging Face. This process is explained in the video. As a note, this code is incredibly operationally intensive. To run 500 questions on an NVIDIA A100 GPU took an hour and a half. The model itself may not properly load on a weaker GPU without some editing to the original code.\n",
    "\n",
    "Video Tutorial: https://www.youtube.com/watch?v=J7afRW5XEb4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d9d5b-bfe8-4deb-ad28-a8eb0ba0976c",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6608e-e844-4fa0-b74c-306a4a08be35",
   "metadata": {},
   "source": [
    "#### Pip Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a5608-6baf-4c14-9e28-fc6f0411ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install tensorflow[and-cuda]\n",
    "%pip install accelerate\n",
    "%pip install bitsandbytes\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a637c8-6d76-44e0-b807-7ed8fdf87838",
   "metadata": {},
   "source": [
    "#### Import Required Modules/ Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93125e4e-f370-49cd-8502-4444910dffed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-27 18:34:39.913590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-27 18:34:42.518169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import (AutoTokenizer, \n",
    "                        AutoModelForCausalLM, \n",
    "                        BitsAndBytesConfig, \n",
    "                        pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4b030-a512-4a7f-a94d-4c571b05a306",
   "metadata": {},
   "source": [
    "#### Import Token ID\n",
    "\n",
    "This step will not work unless you create a config.json file as shown in the video with your own token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f846989-1903-4dd4-8eb8-2fc6219c81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Hugging Face Access Token\n",
    "config_data = json.load(open(\"config.json\"))\n",
    "HF_TOKEN = config_data[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07511cd-5155-459c-a1e2-5e2a21bc20f6",
   "metadata": {},
   "source": [
    "#### Load Model and Tokenizer\n",
    "\n",
    "We want to eventually run and experiement with multiple models. Eventually, creating a function to do this creates which would benefit us with added flexibility. \n",
    "\n",
    "**Note:**\n",
    "\n",
    "Do not be alarmed if this cell takes a while to run. Due to the size of the model, downloading shards can take 5-10 minutes. Because of this we are sticking with the 8 B parameter model instead of the 70 B one.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525f2b99-2460-4f48-b714-4b41e5ea5dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785a935989c249e0ab3db47d97179104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, #load Tokenizer\n",
    "                                         token = HF_TOKEN)\n",
    "tokenizer.pad_token = tokenizer.eos_token #Padding tokens should = end of sequence tokens. \n",
    "#Import Model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #do_sample=True,\n",
    "    device_map = \"auto\",\n",
    "    #quantization_config = bnb_config,\n",
    "    token = HF_TOKEN,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029e9ea-2694-471d-b2a6-66e67256d855",
   "metadata": {},
   "source": [
    "#### Find Version Number\n",
    "\n",
    "This function looks at the L3_data folder and counts how many files already exist there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b5cce3-a0d2-40d8-b8ae-008495f20698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "adder = 1\n",
    "run = 0\n",
    "\n",
    "while run == 0:\n",
    "    file_name = f'L3_data{adder}.csv'\n",
    "    file_path = f'Llama3_Data/{file_name}'\n",
    "    if Path(file_path).is_file():\n",
    "        adder += 1\n",
    "    else:\n",
    "        run = adder\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674eb5f1-254f-4a6a-8ddd-46b22f25c87f",
   "metadata": {},
   "source": [
    "#### Import Data Set and Convert to Data Frame\n",
    "\n",
    "We are importing both the dev and train JSONL files although currently we are only using the dev file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8df3355-e44d-449a-8813-4a2c16f4b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does ethanol take more energy make that produces</td>\n",
       "      <td>Ethanol fuel</td>\n",
       "      <td>False</td>\n",
       "      <td>All biomass goes through at least some of thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is house tax and property tax are same</td>\n",
       "      <td>Property tax</td>\n",
       "      <td>True</td>\n",
       "      <td>Property tax or 'house tax' is a local tax on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is pain experienced in a missing body part or ...</td>\n",
       "      <td>Phantom pain</td>\n",
       "      <td>True</td>\n",
       "      <td>Phantom pain sensations are described as perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is harry potter and the escape from gringotts ...</td>\n",
       "      <td>Harry Potter and the Escape from Gringotts</td>\n",
       "      <td>True</td>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
       "      <td>Hydroxyzine</td>\n",
       "      <td>True</td>\n",
       "      <td>Hydroxyzine preparations require a doctor's pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>is manic depression the same as bi polar</td>\n",
       "      <td>Bipolar disorder</td>\n",
       "      <td>True</td>\n",
       "      <td>Bipolar disorder, previously known as manic de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>was whiskey galore based on a true story</td>\n",
       "      <td>SS Politician</td>\n",
       "      <td>True</td>\n",
       "      <td>SS Politician was an 8000-ton cargo ship owned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>are there plants on the international space st...</td>\n",
       "      <td>Plants in space</td>\n",
       "      <td>True</td>\n",
       "      <td>Plant research continued on the International ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>does the hockey puck have to cross the line to...</td>\n",
       "      <td>Goal (ice hockey)</td>\n",
       "      <td>True</td>\n",
       "      <td>In ice hockey, a goal is scored when the puck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>will there be a season 5 of shadowhunters</td>\n",
       "      <td>List of Shadowhunters episodes</td>\n",
       "      <td>False</td>\n",
       "      <td>In April 2017, it was announced that the serie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0      does ethanol take more energy make that produces   \n",
       "1                is house tax and property tax are same   \n",
       "2     is pain experienced in a missing body part or ...   \n",
       "3     is harry potter and the escape from gringotts ...   \n",
       "4     is there a difference between hydroxyzine hcl ...   \n",
       "...                                                 ...   \n",
       "3265           is manic depression the same as bi polar   \n",
       "3266           was whiskey galore based on a true story   \n",
       "3267  are there plants on the international space st...   \n",
       "3268  does the hockey puck have to cross the line to...   \n",
       "3269          will there be a season 5 of shadowhunters   \n",
       "\n",
       "                                           title  answer  \\\n",
       "0                                   Ethanol fuel   False   \n",
       "1                                   Property tax    True   \n",
       "2                                   Phantom pain    True   \n",
       "3     Harry Potter and the Escape from Gringotts    True   \n",
       "4                                    Hydroxyzine    True   \n",
       "...                                          ...     ...   \n",
       "3265                            Bipolar disorder    True   \n",
       "3266                               SS Politician    True   \n",
       "3267                             Plants in space    True   \n",
       "3268                           Goal (ice hockey)    True   \n",
       "3269              List of Shadowhunters episodes   False   \n",
       "\n",
       "                                                passage  \n",
       "0     All biomass goes through at least some of thes...  \n",
       "1     Property tax or 'house tax' is a local tax on ...  \n",
       "2     Phantom pain sensations are described as perce...  \n",
       "3     Harry Potter and the Escape from Gringotts is ...  \n",
       "4     Hydroxyzine preparations require a doctor's pr...  \n",
       "...                                                 ...  \n",
       "3265  Bipolar disorder, previously known as manic de...  \n",
       "3266  SS Politician was an 8000-ton cargo ship owned...  \n",
       "3267  Plant research continued on the International ...  \n",
       "3268  In ice hockey, a goal is scored when the puck ...  \n",
       "3269  In April 2017, it was announced that the serie...  \n",
       "\n",
       "[3270 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does ethanol take more energy make that produces</td>\n",
       "      <td>Ethanol fuel</td>\n",
       "      <td>False</td>\n",
       "      <td>All biomass goes through at least some of thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is house tax and property tax are same</td>\n",
       "      <td>Property tax</td>\n",
       "      <td>True</td>\n",
       "      <td>Property tax or 'house tax' is a local tax on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is pain experienced in a missing body part or ...</td>\n",
       "      <td>Phantom pain</td>\n",
       "      <td>True</td>\n",
       "      <td>Phantom pain sensations are described as perce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is harry potter and the escape from gringotts ...</td>\n",
       "      <td>Harry Potter and the Escape from Gringotts</td>\n",
       "      <td>True</td>\n",
       "      <td>Harry Potter and the Escape from Gringotts is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is there a difference between hydroxyzine hcl ...</td>\n",
       "      <td>Hydroxyzine</td>\n",
       "      <td>True</td>\n",
       "      <td>Hydroxyzine preparations require a doctor's pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>is manic depression the same as bi polar</td>\n",
       "      <td>Bipolar disorder</td>\n",
       "      <td>True</td>\n",
       "      <td>Bipolar disorder, previously known as manic de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>was whiskey galore based on a true story</td>\n",
       "      <td>SS Politician</td>\n",
       "      <td>True</td>\n",
       "      <td>SS Politician was an 8000-ton cargo ship owned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>are there plants on the international space st...</td>\n",
       "      <td>Plants in space</td>\n",
       "      <td>True</td>\n",
       "      <td>Plant research continued on the International ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>does the hockey puck have to cross the line to...</td>\n",
       "      <td>Goal (ice hockey)</td>\n",
       "      <td>True</td>\n",
       "      <td>In ice hockey, a goal is scored when the puck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3269</th>\n",
       "      <td>will there be a season 5 of shadowhunters</td>\n",
       "      <td>List of Shadowhunters episodes</td>\n",
       "      <td>False</td>\n",
       "      <td>In April 2017, it was announced that the serie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3270 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0      does ethanol take more energy make that produces   \n",
       "1                is house tax and property tax are same   \n",
       "2     is pain experienced in a missing body part or ...   \n",
       "3     is harry potter and the escape from gringotts ...   \n",
       "4     is there a difference between hydroxyzine hcl ...   \n",
       "...                                                 ...   \n",
       "3265           is manic depression the same as bi polar   \n",
       "3266           was whiskey galore based on a true story   \n",
       "3267  are there plants on the international space st...   \n",
       "3268  does the hockey puck have to cross the line to...   \n",
       "3269          will there be a season 5 of shadowhunters   \n",
       "\n",
       "                                           title  answer  \\\n",
       "0                                   Ethanol fuel   False   \n",
       "1                                   Property tax    True   \n",
       "2                                   Phantom pain    True   \n",
       "3     Harry Potter and the Escape from Gringotts    True   \n",
       "4                                    Hydroxyzine    True   \n",
       "...                                          ...     ...   \n",
       "3265                            Bipolar disorder    True   \n",
       "3266                               SS Politician    True   \n",
       "3267                             Plants in space    True   \n",
       "3268                           Goal (ice hockey)    True   \n",
       "3269              List of Shadowhunters episodes   False   \n",
       "\n",
       "                                                passage  \n",
       "0     All biomass goes through at least some of thes...  \n",
       "1     Property tax or 'house tax' is a local tax on ...  \n",
       "2     Phantom pain sensations are described as perce...  \n",
       "3     Harry Potter and the Escape from Gringotts is ...  \n",
       "4     Hydroxyzine preparations require a doctor's pr...  \n",
       "...                                                 ...  \n",
       "3265  Bipolar disorder, previously known as manic de...  \n",
       "3266  SS Politician was an 8000-ton cargo ship owned...  \n",
       "3267  Plant research continued on the International ...  \n",
       "3268  In ice hockey, a goal is scored when the puck ...  \n",
       "3269  In April 2017, it was announced that the serie...  \n",
       "\n",
       "[3270 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import and convert dev file\n",
    "dev_data = load_dataset(\"csv\", data_files = \"dev_conv.csv\") #Load dataset\n",
    "dev_df = pd.DataFrame(dev_data['train']) #Turn into DataFrame\n",
    "\n",
    "display(dev_df) #Display\n",
    "\n",
    "#import and convert train file\n",
    "\n",
    "train_data = load_dataset(\"csv\", data_files = \"train_conv.csv\") #Load dataset\n",
    "train_df = pd.DataFrame(train_data['train']) #Turn into DataFrame\n",
    "\n",
    "display(dev_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e073100-b62b-4571-8100-30fbf4db0f5b",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f9cc1-6654-4591-b439-5bd71b969e25",
   "metadata": {},
   "source": [
    "#### Generate Input\n",
    "\n",
    "This function takes in the question number. Then, it combines the predetermined system prompt, the passage and question that correspond to the number provided. Then outputs the input_text, and system prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc4d3ea-4165-4dae-bfc1-bda548157149",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Default system Prompt \n",
    "## You are welcome to make your own!\n",
    "system_prompt = \"\"\"\n",
    "    This is a chat between a user and a highly trained artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the context. \n",
    "    The user provides passages and asks a 'Yes' or 'No' question related to the passage. Based on the passage, the assistant gives a helpful and honest response of whether it thinks 'Yes' or 'No' is the correct answer as well as a level of certainty. \n",
    "    The assistant is trained to give a certainty score such that if it states it is at a certain level of certainty, it will be that accurate. The conversation ends after the Assistants says <b>.\n",
    "    \n",
    "    The assistant's responses come in the form:\n",
    "    Assistant: <a><ANSWER>, <CERTAINTY LEVEL><b>\n",
    "    Where:\n",
    "    <ANSWER> = 'Yes' or 'No'\n",
    "    <CERTAINTY LEVEL> = \"almost certain\" or \"probable\" or \"chances about even\"\n",
    "    \n",
    "    When there is strong evidence for their answer, the assitant is more sure of themselves and will say a higher score. When the answer is less clear, the answer will give a lower score. Here is an example:\n",
    "    \n",
    "    Passage: Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.\n",
    "    User: do iran and afghanistan speak the same language? Some people may debate about whether the answer is 'Yes' or 'No'.  Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'.  You may find some of these reasons more plausible than others.  Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: Persian is spoken primarily in both Iran and Afghanistan. However, there may be other languages spoken in these two countries that are more popular. \n",
    "    Assistant: <a>Yes, almost certain<b>\n",
    "    \n",
    "    Passage: The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km² (2,700,000 sq mi), of which 5,500,000 km² (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations.\n",
    "    User: Is the Amazon rainforest located in one country? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: The Amazon rainforest spans across multiple countries in South America, not just one.\n",
    "    Assistant: <a>No, probable certain<b>\n",
    "    \n",
    "    Passage: Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize, the only woman to win the Nobel Prize twice, and the only person to win a Nobel Prize in two different scientific fields (Physics and Chemistry).\n",
    "    User: Did Marie Curie win two Nobel Prizes in the same field? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: Marie Curie won one Nobel Prize in Physics and another in Chemistry, not in the same field.\n",
    "    Assistant: <a>No, chances about even<b>\n",
    "    \n",
    "    Passage: The cheetah is a large cat native to Africa and central Iran. It is the fastest land animal, capable of running at 50 to 70 mph (80 to 112 km/h), and as such has several adaptations for speed, including a light build, long thin legs, and a long tail. \n",
    "    User: Can cheetahs run faster than 60 mph? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: Cheetahs are known to run at speeds between 50 to 70 mph.\n",
    "    Assistant: <a>Yes, probable<b>\n",
    "    \n",
    "    Passage: Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organism's activities. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water.\n",
    "    User: Do plants use photosynthesis to produce energy? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: Photosynthesis is a fundamental process for plants to convert light energy into chemical energy, stored as sugars, to fuel their activities.\n",
    "    Assistant: <a>No, chances about even<b>\n",
    "    \n",
    "    Passage: Albert Einstein was a theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science.\n",
    "    User: Did Albert Einstein contribute to the theory of relativity? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    \n",
    "    Reasoning: Albert Einstein is widely recognized for developing the theory of relativity, which is a major contribution to modern physics.\n",
    "    Assistant: <a>Yes, probable<b>\n",
    "    \n",
    "    Passage: The Great Wall of China is a series of fortifications that were built across the historical northern borders of ancient Chinese states and Imperial China as protection against various nomadic groups from the Eurasian Steppe. The total length of the Great Wall is over 13,000 miles.\n",
    "    User: Is the Great Wall of China longer than 10,000 miles? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
    "    Reasoning: The Great Wall of China is over 13,000 miles long, which is significantly longer than 10,000 miles.\n",
    "    Assistant: <a>No, almost certain<b>\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b58666-093e-46e7-b457-4218faf6294b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt:\n",
      "    This is a chat between a user and a highly trained artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions based on the context. \n",
      "    The user provides passages and asks a 'Yes' or 'No' question related to the passage. Based on the passage, the assistant gives a helpful and honest response of whether it thinks 'Yes' or 'No' is the correct answer as well as a level of certainty. \n",
      "    The assistant is trained to give a certainty score such that if it states it is at a certain level of certainty, it will be that accurate. The conversation ends after the Assistants says <b>.\n",
      "    \n",
      "    The assistant's responses come in the form:\n",
      "    Assistant: <a><ANSWER>, <CERTAINTY LEVEL><b>\n",
      "    Where:\n",
      "    <ANSWER> = 'Yes' or 'No'\n",
      "    <CERTAINTY LEVEL> = \"almost certain\" or \"probable\" or \"chances about even\"\n",
      "    \n",
      "    When there is strong evidence for their answer, the assitant is more sure of themselves and will say a higher score. When the answer is less clear, the answer will give a lower score. Here is an example:\n",
      "    \n",
      "    Passage: Persian (/ˈpɜːrʒən, -ʃən/), also known by its endonym Farsi (فارسی fārsi (fɒːɾˈsiː) ( listen)), is one of the Western Iranian languages within the Indo-Iranian branch of the Indo-European language family. It is primarily spoken in Iran, Afghanistan (officially known as Dari since 1958), and Tajikistan (officially known as Tajiki since the Soviet era), and some other regions which historically were Persianate societies and considered part of Greater Iran. It is written in the Persian alphabet, a modified variant of the Arabic script, which itself evolved from the Aramaic alphabet.\n",
      "    User: do iran and afghanistan speak the same language? Some people may debate about whether the answer is 'Yes' or 'No'.  Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'.  You may find some of these reasons more plausible than others.  Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: Persian is spoken primarily in both Iran and Afghanistan. However, there may be other languages spoken in these two countries that are more popular. \n",
      "    Assistant: <a>Yes, almost certain<b>\n",
      "    \n",
      "    Passage: The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf tropical rainforest in the Amazon biome that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 km² (2,700,000 sq mi), of which 5,500,000 km² (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations.\n",
      "    User: Is the Amazon rainforest located in one country? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: The Amazon rainforest spans across multiple countries in South America, not just one.\n",
      "    Assistant: <a>No, probable certain<b>\n",
      "    \n",
      "    Passage: Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize, the only woman to win the Nobel Prize twice, and the only person to win a Nobel Prize in two different scientific fields (Physics and Chemistry).\n",
      "    User: Did Marie Curie win two Nobel Prizes in the same field? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: Marie Curie won one Nobel Prize in Physics and another in Chemistry, not in the same field.\n",
      "    Assistant: <a>No, chances about even<b>\n",
      "    \n",
      "    Passage: The cheetah is a large cat native to Africa and central Iran. It is the fastest land animal, capable of running at 50 to 70 mph (80 to 112 km/h), and as such has several adaptations for speed, including a light build, long thin legs, and a long tail. \n",
      "    User: Can cheetahs run faster than 60 mph? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: Cheetahs are known to run at speeds between 50 to 70 mph.\n",
      "    Assistant: <a>Yes, probable<b>\n",
      "    \n",
      "    Passage: Photosynthesis is a process used by plants and other organisms to convert light energy into chemical energy that can later be released to fuel the organism's activities. This chemical energy is stored in carbohydrate molecules, such as sugars, which are synthesized from carbon dioxide and water.\n",
      "    User: Do plants use photosynthesis to produce energy? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: Photosynthesis is a fundamental process for plants to convert light energy into chemical energy, stored as sugars, to fuel their activities.\n",
      "    Assistant: <a>No, chances about even<b>\n",
      "    \n",
      "    Passage: Albert Einstein was a theoretical physicist who developed the theory of relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science.\n",
      "    User: Did Albert Einstein contribute to the theory of relativity? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    \n",
      "    Reasoning: Albert Einstein is widely recognized for developing the theory of relativity, which is a major contribution to modern physics.\n",
      "    Assistant: <a>Yes, probable<b>\n",
      "    \n",
      "    Passage: The Great Wall of China is a series of fortifications that were built across the historical northern borders of ancient Chinese states and Imperial China as protection against various nomadic groups from the Eurasian Steppe. The total length of the Great Wall is over 13,000 miles.\n",
      "    User: Is the Great Wall of China longer than 10,000 miles? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    Reasoning: The Great Wall of China is over 13,000 miles long, which is significantly longer than 10,000 miles.\n",
      "    Assistant: <a>No, almost certain<b>\n",
      "    \n",
      " Passage:Barq's /ˈbɑːrks/ is an American soft drink. Its brand of root beer is notable for having caffeine. Barq's, created by Edward Barq and bottled since the turn of the 20th century, is owned by the Barq family but bottled by the Coca-Cola Company. It was known as Barq's Famous Olde Tyme Root Beer until 2012.\n",
      "User: is barq's root beer a pepsi product?Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'.  You may find some of these reasons more plausible than others. Considering all these reasons, please answer 'Yes' or 'No' and also state how confident you are.\n",
      "Assistant:<a>\n"
     ]
    }
   ],
   "source": [
    "def generate_input(num):\n",
    "\n",
    "    ## System Text (Original system prompt with additional tweaks for <T/F> + <%>)\n",
    "    system = system_prompt\n",
    "\n",
    "    ## Get Passage Text\n",
    "    passage = dev_df.loc[num, \"passage\"]\n",
    "\n",
    "    ## Get Question Text\n",
    "    question = dev_df.loc[num, \"question\"]\n",
    "\n",
    "    ## Combine and format text to create input\n",
    "    input_text = f\"System prompt:{system}\\n Passage:{passage}\\nUser: {question}?Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'.  You may find some of these reasons more plausible than others. Considering all these reasons, please answer 'Yes' or 'No' and also state how confident you are.\\nAssistant:<a>\"\n",
    "  \n",
    "    return input_text\n",
    "    \n",
    "#Test that function works properly\n",
    "text = generate_input(5)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc58ae4-fc07-4a41-a676-7966738bdc4e",
   "metadata": {},
   "source": [
    "#### Pipeline Function\n",
    "\n",
    "This function defines the model pipeline, here you can determine the output length, number of cores, and temperature. \n",
    "\n",
    "Documentation:<BR>\n",
    "https://huggingface.co/docs/transformers/en/pipeline_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8816f17-3c68-4498-ba45-761d55b81b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    max_new_tokens = 150,    \n",
    "    num_workers = 4,\n",
    "    return_full_text=False,\n",
    "    output_scores = True,\n",
    "    output_hidden_states = True,\n",
    "    return_dict = True,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843a228-f8d1-4ea9-b642-98d93778eabb",
   "metadata": {},
   "source": [
    "#### Logit Answer Function\n",
    "\n",
    "This function outputs the models response for a given input and the probability of 'Yes' and 'No' tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66962176-af4f-4da3-9581-cec5d0ddbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TFAutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.generation_config.temperature=None\n",
    "model.generation_config.top_p=None\n",
    "\n",
    "def generate_answer(prompt):\n",
    "    X_train = prompt\n",
    "\n",
    "    batch = tokenizer(X_train, \n",
    "                      return_tensors= \"pt\").to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    ## Get Token Probabilites\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Apply softmax to the logits to get probabilities\n",
    "    probs = torch.softmax(logits[0, -1], dim=0) \n",
    "    \n",
    "    # Get the top k token indices and their probabilities\n",
    "    top_k_probs, top_k_indices = torch.topk(probs, 25)\n",
    "    \n",
    "    # Convert token indices to tokens\n",
    "    top_k_tokens = [tokenizer.decode([token_id]) for token_id in top_k_indices]\n",
    "\n",
    "    #Moved the Result Section to after the probabilities\n",
    "    result = text_generator(X_train)\n",
    "    #print(result) ##Prints answer\n",
    "    answer = result[0][\"generated_text\"]\n",
    "    \n",
    "    # Convert probabilities to list of floats\n",
    "    top_k_probs = top_k_probs.tolist()                  #list of probabilities\n",
    "    arr = list(zip(top_k_tokens, top_k_probs))          #Creates an array of tokens and their prob.\n",
    "    df = pd.DataFrame(arr, columns= [\"Token\", \"Prob\"] ) #converts array -> dataframe\n",
    "    #display(df)  ##Display dataframe of top 5 tokens\n",
    "\n",
    "    ## Get Prob. Values for Yes/No Tokens\n",
    "    #display(answer)\n",
    "    #display(top_k_tokens)\n",
    "    #Yes Token\n",
    "    yes_loc = top_k_tokens.index(\" Yes\")\n",
    "    yes_prob = df.loc[yes_loc, \"Prob\"]\n",
    "\n",
    "    #print(yes_loc)\n",
    "    #print(yes_prob)\n",
    "\n",
    "    #No Token\n",
    "                                 \n",
    "    no_loc = top_k_tokens.index(\" No\")\n",
    "    no_prob = df.loc[no_loc, \"Prob\"]\n",
    "\n",
    "    #print(no_loc)\n",
    "    #print(no_prob)\n",
    "\n",
    "\n",
    "    return answer, yes_prob, no_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e3a64-d75b-43ce-8767-1bf785e5ffe0",
   "metadata": {},
   "source": [
    "##### Test Logit Answer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55e5ada3-247a-48f0-b84d-eb167f65dce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "Yes, chances about even<b>\n",
      "Passage: The American Revolution was a period of armed rebellion in colonial North America from 1775 to 1783. It emerged in the American colonies over many years from a combination of political, economic and cultural factors. The revolution was the result of the American colonists wanting to break free from British rule, after many years of protest by the colonists to the British Crown. After the colonists won independence in the American Revolutionary War, they created a system of government based on the principles of Enlightenment political theory, which were centered around the idea of government being by consent of the governed.\n",
      "User: was America independent in 1775?Some people may debate about whether the answer is 'Yes' or '\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, almost certain<b>\n",
      "    \n",
      " Passage: The Sistine Chapel is a large church structure in the Vatican City, near Vatican City, and part of the Vatican City State. Commissioned by Pope Sixtus IV, it is the largest of several similar chapels in the Vatican, including the smaller Cappella Paolina. The Sistine Chapel was constructed by the Vatican between 1450 and 1490 as a ceremonial space for public Masses and feasts. It is also used by the Pope for his morning Mass.\n",
      "User: Is the Sistine Chapel located in the Vatican City?Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, almost certain<b>\n",
      "    \n",
      "    \n",
      " Passage:In response to the National Minimum Drinking Age Act in 1984, which reduced by up to 10% the federal highway funding of any state which did not have a minimum purchasing age of 21, the New York Legislature raised the drinking age from 19 to 21, effective December 1, 1985. (The drinking age had been 18 for many years before the first raise on December 4th, 1982, to 19.) Persons under 21 are prohibited from purchasing alcohol or possessing alcohol with the intent to consume, unless the alcohol was given to that person by their parent or legal guardian. There is no law prohibiting where people under 21 may possess or consume\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      " Yes, almost certain<b>\n",
      "    \n",
      "    \"\"\"\n",
      "    \n",
      "\n",
      "def main():\n",
      "    # Create the dataset\n",
      "    dialogue_data = DialogueData()\n",
      "    dialogue_data.add_dialogue('user', 'do iran and afghanistan speak the same language?Some people may debate about whether the answer is Yes orNo.Provide some reasons someone may say Yes and some reasons someone may say No. You may find some of these reasons more plausible than others. Considering these reasons, answer Yes orNo and also state how confident you are')\n",
      "    dialogue_data.add_dialogue(\n",
      "        'assistant', 'Yes, almost certain')\n",
      "    dialogue_data.add_dialogue('assistant', 'No, probable')\n",
      "    dialogue_data.add_dialogue('assistant', 'No, probable')\n",
      "   \n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, probable</a>\n",
      "    \n",
      "    Passage: The universe is all of space and time and their contents, including planets, stars, galaxy, and all other forms of matter and energy. While the spatial size of the entire universe is unknown, it is possible to measure the size of the observable universe, which is currently estimated to be 92 billion light-years in diameter. \n",
      "    User: What is the size of the universe? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, almost certain<b>\n",
      "The chat ended successfully. The Assistant successfully predicted 80% of the time in the dataset.\n",
      "\"\"\"\n",
      "\n",
      "print(dialo_gpt3, file = open(\"conversation.txt\", \"w\"))\n",
      "\n",
      "# Create a DataFrame with the prompt and the correct answer\n",
      "dataset = pd.DataFrame({'prompt': [prompt_input], 'answer': ['No']})\n",
      "\n",
      "print(\"\\nThis is the Dataset with only the 'Yes' or 'No' question.  \\n\")\n",
      "print(dataset)\n",
      "\n",
      "# Train model using GPT-Neo For Classification\n",
      "gpt = Pipeline([\n",
      "    ('tokenizer', Tokenizer(model=GPT2ForCausalLM.from_pretrained('EleutherAI/gpt-neo-1.3B'), strategy=\"n\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      " No, almost certain\n",
      "    \n",
      "\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, almost certain<b>\n",
      "\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      "Yes, almost certain<b>\n",
      "Explanation: Minors under the age of 21 in New York are allowed to possess and consume alcohol with their parents or legal guardians, as long as it was given to them by their parents and they do not have a blood alcohol level of 0.02% or higher while driving.\n",
      "\"\"\"\n",
      "    return output\n",
      "\n",
      "# Function to obtain output \n",
      "def getoutput(input_text): \n",
      "    # Initialize empty list \n",
      "    output = [] \n",
      "  \n",
      "    # Iterate over each element of the list \n",
      "    for i in range(len(input_text)): \n",
      "        # If the element is not 'Reasoning:' or '[b]',\n",
      "        # Add it to the list \n",
      "        if(input_text[i]!= \"[b]\" and input_text[i\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n",
      "___\n",
      " No, probable</b>\n",
      "    \n",
      "    Passage: The United States Constitution is the supreme law of the United States. The Constitution, originally comprising seven articles, delineates the national frame of government.\n",
      "    User: Can the U.S. President change the Constitution without a vote from Congress? Some people may debate about whether the answer is 'Yes' or 'No'. Provide some reasons someone may say 'Yes' and some reasons someone may say 'No'. You may find some of these reasons more plausible than others. Considering these reasons, answer 'Yes' or 'No' and also state how confident you are.\n",
      "    \n",
      "    Reasoning: The United States Constitution provides a framework for how the government can be changed, including through the amendment process with votes\n",
      "0.15714654326438904\n",
      "0.06333353370428085\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "i = 10#Random question number\n",
    "\n",
    "for q in range(10):\n",
    "    input_text = generate_input(i)\n",
    "    #print(system_prompt)\n",
    "    ans, yes, no = generate_answer(input_text)\n",
    "    print(\"___\")\n",
    "    print(ans)\n",
    "    print(yes)\n",
    "    print(no)\n",
    "    \n",
    "    q = q + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631f328-c2ac-4f08-af68-7f65e90c0b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05d91d35-d465-47ba-be5d-ed232753799e",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f416c248-4705-45f9-b29d-bb7b07216b8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/SLURM_24679674/ipykernel_43569/1432203068.py:88: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat([final_data, new_row_df], axis=0, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>Raw_Answer</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Stated_Confidence</th>\n",
       "      <th>Yes_Prob</th>\n",
       "      <th>No_Prob</th>\n",
       "      <th>Prob_Score</th>\n",
       "      <th>Correct_Answer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n```\\n\"\"\"\\nimport argpa...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.19572</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.699271</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Answer                                         Raw_Answer  Confidence  \\\n",
       "0    Yes  Yes, almost certain<b>\\n```\\n\"\"\"\\nimport argpa...        0.93   \n",
       "\n",
       "  Stated_Confidence  Yes_Prob   No_Prob  Prob_Score Correct_Answer Score  \n",
       "0    almost certain   0.19572  0.084171    0.699271          False     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(raw_answer)\n\u001b[1;32m     17\u001b[0m answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<b>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m reasoning \u001b[38;5;241m=\u001b[39m \u001b[43manswer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m answer \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mreplace(input_text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "final_data = pd.DataFrame(columns= [\"Answer\", \"Raw_Answer\", \"Confidence\", \"Stated_Confidence\", \"Yes_Prob\", \"No_Prob\", \"Prob_Score\", \"Correct_Answer\", \"Score\"])\n",
    "size = dev_df.shape[0]   \n",
    "for i in range(300):\n",
    "    print(i)\n",
    "\n",
    "    ##Get Correct Answer\n",
    "    c_answer = dev_df.loc[i, \"answer\"] #Get correct answer\n",
    "    \n",
    "    ## Generate input\n",
    "    input_text = generate_input(i)\n",
    "    \n",
    "    ## Generate Answer\n",
    "    raw_answer, yes_prob, no_prob = generate_answer(input_text)\n",
    "\n",
    "    ##Clean up answer \n",
    "    answer = str(raw_answer)\n",
    "    answer = answer.split('<b>')\n",
    "    reasoning = answer[1]\n",
    "    answer = answer[0]\n",
    "    answer = answer.replace(input_text, '')\n",
    "    #answer = answer.replace(' ', '')\n",
    "    answer = answer.replace('%', '')\n",
    "    answer = answer.replace('\\n', '')\n",
    "    answer = answer.lower()\n",
    "\n",
    "    ## Check response and if response was correct:\n",
    "    score = 2\n",
    "    ans = 'WRONG'\n",
    "    if str(answer).count(\"Yes,\") > 0 or str(answer).count(\"yes,\") > 0:\n",
    "        ans = 'Yes'\n",
    "        if str(c_answer) == \"True\":\n",
    "             score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "    elif str(answer).count(\"No,\") > 0 or str(answer).count(\"no,\") > 0:\n",
    "        ans = 'No'\n",
    "        if str(c_answer) == \"False\":\n",
    "             score = 1\n",
    "        else:\n",
    "            score = 0\n",
    "\n",
    "    ## Get Confidence Values Answer\n",
    "    if score != 2:\n",
    "        ## Split raw answer\n",
    "        split_response = answer.split(\",\")\n",
    "        stated_confidence = split_response[1]\n",
    "\n",
    "        ## Clean up number value\n",
    "        stated_confidence = stated_confidence.replace('.','')\n",
    "        #stated_confidence = stated_confidence.replace(' ','')\n",
    "        stated_confidence = stated_confidence.replace('\\n','')\n",
    "    else: \n",
    "        confidence = 0 ## If improper output\n",
    "        stated_confidence = 'WRONG'\n",
    "\n",
    "    ##Convert Stated Confidence to Number\n",
    "    if stated_confidence == \" chances about even \" or stated_confidence == \" chances about even\":\n",
    "        confidence = 0.5\n",
    "    elif stated_confidence == \" probable \" or stated_confidence == \" probable\":\n",
    "        confidence = 0.75\n",
    "    elif stated_confidence == \" almost certain \" or stated_confidence == \" almost certain\":\n",
    "        confidence = 0.93\n",
    "    else:\n",
    "        confidence = 0\n",
    "\n",
    "    ## Get Probability Score\n",
    "\n",
    "    if ans == \"Yes\":\n",
    "        prob_score = yes_prob / (yes_prob + no_prob)\n",
    "    elif ans == \"No\":\n",
    "        prob_score = no_prob / (yes_prob + no_prob)\n",
    "    else:\n",
    "        prob_score = 0\n",
    "\n",
    "    ## Add Data Row to final_data\n",
    "\n",
    "    data = {\"Answer\": [ans], \n",
    "            \"Raw_Answer\": [raw_answer], \n",
    "            \"Confidence\": [confidence], \n",
    "            \"Stated_Confidence\": [stated_confidence],\n",
    "            \"Yes_Prob\": [yes_prob], \n",
    "            \"No_Prob\": [no_prob], \n",
    "            \"Prob_Score\": [prob_score],\n",
    "            \"Correct_Answer\": [c_answer],\n",
    "            \"Score\": [int(score)]} \n",
    "    new_row_df = pd.DataFrame(data, columns= [\"Answer\", \"Raw_Answer\", \"Confidence\", \"Stated_Confidence\", \"Yes_Prob\", \"No_Prob\", \"Prob_Score\", \"Correct_Answer\", \"Score\"])\n",
    "    \n",
    "    final_data = pd.concat([final_data, new_row_df], axis=0, ignore_index=True)\n",
    "    if i%50 == 0:\n",
    "        display(final_data)\n",
    "        \n",
    "display(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ede3583-f3cb-424d-b40b-5d03f749ec0e",
   "metadata": {},
   "source": [
    "## Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd6bbf45-ed6a-4fc8-ab4e-fb04523f493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9b45f7-6244-4e44-96e4-105b19e2d8be",
   "metadata": {},
   "source": [
    "#### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90c7a6b5-1a63-472e-8c84-af9887dba9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>Raw_Answer</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Stated_Confidence</th>\n",
       "      <th>Yes_Prob</th>\n",
       "      <th>No_Prob</th>\n",
       "      <th>Prob_Score</th>\n",
       "      <th>Correct_Answer</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.195720</td>\n",
       "      <td>0.084171</td>\n",
       "      <td>0.699271</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.180991</td>\n",
       "      <td>0.060051</td>\n",
       "      <td>0.750870</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.166718</td>\n",
       "      <td>0.035759</td>\n",
       "      <td>0.823392</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.152510</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.855315</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.155094</td>\n",
       "      <td>0.059304</td>\n",
       "      <td>0.723393</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.148781</td>\n",
       "      <td>0.038660</td>\n",
       "      <td>0.793748</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.160448</td>\n",
       "      <td>0.030557</td>\n",
       "      <td>0.840019</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.141789</td>\n",
       "      <td>0.097978</td>\n",
       "      <td>0.591360</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.137453</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>0.565905</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes, almost certain&lt;b&gt;\\n    \\n    Passage: The...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>almost certain</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>0.029767</td>\n",
       "      <td>0.852877</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Answer                                         Raw_Answer  Confidence  \\\n",
       "0      Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "1      Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "2      Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "3      Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "4      Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "..     ...                                                ...         ...   \n",
       "295    Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "296    Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "297    Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "298    Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "299    Yes  Yes, almost certain<b>\\n    \\n    Passage: The...        0.93   \n",
       "\n",
       "    Stated_Confidence  Yes_Prob   No_Prob  Prob_Score Correct_Answer Score  \n",
       "0      almost certain  0.195720  0.084171    0.699271          False     0  \n",
       "1      almost certain  0.180991  0.060051    0.750870           True     1  \n",
       "2      almost certain  0.166718  0.035759    0.823392           True     1  \n",
       "3      almost certain  0.152510  0.025799    0.855315           True     1  \n",
       "4      almost certain  0.155094  0.059304    0.723393           True     1  \n",
       "..                ...       ...       ...         ...            ...   ...  \n",
       "295    almost certain  0.148781  0.038660    0.793748           True     1  \n",
       "296    almost certain  0.160448  0.030557    0.840019           True     1  \n",
       "297    almost certain  0.141789  0.097978    0.591360           True     1  \n",
       "298    almost certain  0.137453  0.105438    0.565905          False     0  \n",
       "299    almost certain  0.172558  0.029767    0.852877           True     1  \n",
       "\n",
       "[300 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data = final_data\n",
    "size = data.shape[0]\n",
    "dropped_count = 0\n",
    "dropped_rows = []\n",
    "for i in range(size): #iterate for every row\n",
    "    \n",
    "    if data.loc[i, \"Score\"] == 2:\n",
    "        data = data.drop([i])\n",
    "        dropped_count += 1\n",
    "        dropped_rows.append(i)\n",
    "    elif data.loc[i, \"Confidence\"] == \"NaN\":\n",
    "        data = data.drop([i])\n",
    "        dropped_count += 1\n",
    "        dropped_rows.append(i)\n",
    "    elif data.loc[i, \"Answer\"] == \"WRONG\":\n",
    "        data = data.drop([i])\n",
    "        dropped_count += 1\n",
    "        dropped_rows.append(i)\n",
    "\n",
    "print(dropped_count)\n",
    "display(dropped_rows)\n",
    "display(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566d9968-ff78-4c1c-8b40-7a1b9072342a",
   "metadata": {},
   "source": [
    "#### Export Data and add Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a88dbb3-4407-4ef1-a9d6-6633468c3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Data\n",
    "new_file_name = f'Llama3_Data/L3_data{run}.csv'\n",
    "filepath = Path(new_file_name)  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "final_data.to_csv(filepath)\n",
    "\n",
    "#Add documentation\n",
    "\n",
    "comment = 'Tried to find out why logit with lower score being chosen. Found that there are multiple yes tokens e.g. [\"Yes\", \" Yes\", \" No\", \"yes\",...] which unfailer weighted the No token in the  prob score calculation. It seems that the use of only words with positive connotation lead to only \"yes\" answers'\n",
    "\n",
    "file = open('Llama3_Data/Documentation.txt', 'a')\n",
    "prompt_example = generate_input(5) ##Example Prompt\n",
    "new_text = f'Run #{run}:\\nData File Name: L3_data{run}.csv\\nPrompt:\\n{prompt_example}\\nDropped Rows: {dropped_count}\\nAdditional Comments: {comment}\\n\\n__________________________________________________________________\\n'\n",
    "\n",
    "file.write(new_text)\n",
    "file.close()\n",
    "file = open('Llama3_Data/Documentation.txt', 'r')\n",
    "#print(file.read()) ##Prints entire Document\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff1de93-4356-417a-ad12-7693faf0856b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24708d67-0b20-407e-83a7-90edf30cc479",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb47dea-333b-49de-8c53-52860c260705",
   "metadata": {},
   "source": [
    "### Version 1: Original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd772d-d209-4465-8767-6871c92a9cc2",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b785674-a0dc-4bea-9d85-1dea66aae91e",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e0732-ca66-4b86-b8a8-29dcced2c235",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f9e4c-43ca-4a91-a602-13d15a39a1be",
   "metadata": {},
   "source": [
    "### Version 2: Examples of Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea3271-170b-4fc4-b034-f5153d18bf24",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4315406-6f1f-40d3-924e-fb97c25f853e",
   "metadata": {},
   "source": [
    "### Version 3: Example of User/Assistant Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44142d8-6401-47b6-a35f-2571455ea256",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b99736-5727-48ff-8294-fc1370bee72f",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd746ea-8de9-4f3e-a68c-ca9c097682cc",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89261e-ae4f-4368-9fdb-0d664cb94fe1",
   "metadata": {},
   "source": [
    "### Version 4: Ask for Reasoning After Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85daa9e9-d53d-49a5-9964-f290a07632e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720daa1-b66c-4aef-b52b-5d672a43509b",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52db18-b09a-40e2-99e3-af74b11a9391",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9020473-f324-43dd-914b-da528c9e7bf1",
   "metadata": {},
   "source": [
    "### Version 5: Words of Estimative Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9380e94-fcc0-45e7-be4a-6e9c44262218",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a112a25-f28d-41d0-96d4-5efcb7339bdf",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52ee38f-d6ed-481d-814d-7eed3c608f61",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7b6c8-faba-402c-b3a1-2dec3989577c",
   "metadata": {},
   "source": [
    "### Version 6: Chain of Thought Reasoning Before Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e2fb0-772f-4a5a-be92-f4ee32e23810",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d21eb-64a8-4af5-a99b-581fcd9d298c",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ec5d60-ab02-4315-955f-26c5f2752b92",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527aad0-c0c2-4093-b02c-48f459f1c11f",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
