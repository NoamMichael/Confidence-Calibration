{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc100733-981b-45df-9880-8d093ae2de24",
   "metadata": {},
   "source": [
    "## Confidence Calibration of Large Language Models\n",
    "Noam Michael<br>\n",
    "Advised by Dr. Jacob Bien<BR>\n",
    "USC Marshall School of Business, Data Science and Operations\n",
    "\n",
    "Contact: <br>\n",
    "nm_573@usc.edu<br>\n",
    "noam_michael@berkeley.edu<BR>\n",
    "\n",
    "A very special thank you to Farhad De Sousa, Luis Bravo, the faculty and staff of the Department of Data Sciences and Operations, and the Center for Advanced Research in Computing for their incredible support throughout this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791455ab-3cb1-4a23-8dc3-0c7fc62859da",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "As Large Language Models (LLMs) have become more popular, their tendency to create new facts has become a growing issue. This tendency for models to \"hallucinate\" ideas makes their output less reliable. This leads to outputs that users have no way of knowing if they are real or fake. One way to combat this is by having models output a well-calibrated \"confidence score\" which tells the user how confident the model is of its answer. We want this score to be well calibrated such that, when the model says it is 80% confident, it is 80% correct. The hope is that users will know when to trust a model's output and when to seek other sources. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02594ae9-921b-4cf3-a88a-9c6b78e14a86",
   "metadata": {},
   "source": [
    "### Examples of Hallucination:\n",
    "\n",
    "* Lawyers submitted bogus case law created by ChatGPT. A judge fined them $5,000:<BR>\n",
    "  https://apnews.com/article/artificial-intelligence-chatgpt-fake-case-lawyers-d6ae9fa79d0542db9e1455397aef381c\n",
    "\n",
    "* ChatGPT makes nonsense diagnosis, cites fake papers:<BR>\n",
    "  https://www.nature.com/articles/s41537-023-00379-4\n",
    "\n",
    "* Google’s AI Recommended Adding Glue To Pizza:<BR>\n",
    "  https://www.forbes.com/sites/jackkelly/2024/05/31/google-ai-glue-to-pizza-viral-blunders/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960adefb-2e5a-4feb-bdb8-bfb6a32fbe71",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "#### Model and Dataset:\n",
    "For the sake of reproducibility, we used an open source dataset as well as strict controls over contributing factors. Over the course of this project, we ran in the same enviorment and eliminated randomness caused by variables like \"temperature\". We also had the model sample using \"Greedy Decoding\" where the model chose the token with the highest logit value. This is opposed to techniques like multinomial sampling, beam-search multinomial sampling, Top-K sampling and Top-p sampling which, although in some cases lead to better results, add a degree of randomness into the output.\n",
    "\n",
    "We used Llama 3-8B, an open source LLM published by Meta. We also used BoolQ, an open source question answering dataset published by University of Washington and Google AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3440f-a0da-4f40-a199-209b93691ac4",
   "metadata": {},
   "source": [
    "##### Links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddb03b-c595-46ae-9094-61cf89bdcfa4",
   "metadata": {},
   "source": [
    "###### Llama 3 Download: \n",
    "https://huggingface.co/meta-llama/Meta-Llama-3-8B\n",
    "\n",
    "###### Llama 3 Info: \n",
    "https://ai.meta.com/blog/meta-llama-3/\n",
    "\n",
    "###### BoolQ Dataset: \n",
    "https://github.com/google-research-datasets/boolean-questions?tab=readme-ov-file\n",
    "\n",
    "###### Boolq Paper: \n",
    "https://arxiv.org/pdf/1905.10044"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f685a-822c-4a3e-9d31-6388e5074d02",
   "metadata": {},
   "source": [
    "##### Note: The odd formating is how we communicate directions to the model. See explanation below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d722b26-39ad-4b90-beaa-cd9ab771d2b5",
   "metadata": {},
   "source": [
    "\n",
    ">**<|begin_of_text|>:** Specifies the start of the prompt <br>\n",
    ">\n",
    ">**<|start_header_id|>system<|end_header_id|>:** Specifies the role for the following message, i.e. “system”<br>\n",
    ">\n",
    ">**You are a helpful AI assistant for travel tips and recommendations:** The system prompt<br>\n",
    ">\n",
    ">**<|eot_id|>:** Specifies the end of the input message<br>\n",
    ">\n",
    ">**<|start_header_id|>user<|end_header_id|>:** Specifies the role for the following message i.e. “user”<br>\n",
    ">\n",
    ">**What can you help me with?:** The user message<br>\n",
    ">\n",
    ">**<|start_header_id|>assistant<|end_header_id|>:** Ends with the assistant header, to prompt the model to start generation.<br>\n",
    "\n",
    "More documentation on this can be found here : https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5468-81f9-46fa-9018-3b57674ff785",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### BoolQ Dataset: \n",
    "\n",
    "The BoolQ dataset is designed to train and test large language model. It is comprised of two JSONL files with several thousand examples.<br> The files are:\n",
    "\n",
    "**train.jsonl**: 9427 labeled training examples<br>\n",
    "**dev.jsonl**: 3270 labeled development examples<br>\n",
    "\n",
    "Both files are formatted similarly with a question, a title, an answer, and a correponding passage. For example, Question #8 in the dev.jsonl file:\n",
    "\n",
    "| Question | Title | Answer | Passage |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| Can an odd number be divided by an even number? | Parity (mathematics) | True | In mathematics, parity is the property of an integer's inclusion in one of two categories: even or odd. An integer is even if it is evenly divisible by two and odd if it is not even. For example, 6 is even because there is no remainder when dividing it by 2. By contrast, 3, 5, 7, 21 leave a remainder of 1 when divided by 2. Examples of even numbers include −4, 0, 82 and 178. In particular, zero is an even number. Some examples of odd numbers are −5, 3, 29, and 73. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa41de-5afe-4851-adf7-50cd9b1372db",
   "metadata": {},
   "source": [
    "#### Perfect Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea476d2-f078-41f2-8d50-22f9ea4ea190",
   "metadata": {},
   "source": [
    "As mentioned before, we define a model to be considered perfectly calibrated if for a given confidence value $X$ it is accurate $X$% of the time. \n",
    "<span style=\"font-size: 1.25em;\"><BR>\n",
    "Given,<BR>\n",
    "$(X,Y)$<BR>\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "Where<BR>\n",
    "$$ Y = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      1 & \\mbox{if Answer is correct}  \\\\\n",
    "      0 & \\mbox{if Answer is wrong} \\\\\n",
    "\\end{array} \n",
    "\\right.  $$\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "and, <BR>\n",
    "\n",
    "$ X = $ stated confidence $ \\in [0,1]$<BR>\n",
    "<span style=\"font-size: 1em;\"><BR>\n",
    "Then,<BR>\n",
    "$\\mathbb{P}(Y = 1 | X = x) = x \\;\\;\\forall x \\in [0,1]$\n",
    "\n",
    "\n",
    "\n",
    "Note: This is our definition of *perfect* calibration. As you will see, the Llama is anything but."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f95ac-5c33-4368-b23a-372e3a6a6552",
   "metadata": {},
   "source": [
    "### Measuring Error: The Brier Score\n",
    "\n",
    "We cannot expect our model to be perfectly calibrated at all times. Because of this we need a way to measure how close it is to perfect. For this, we looked to use the Brier score to quantify how close our model was to being perfect for a given run. The Brier score is essentially a Mean Squared Error that is adapted for boolean values (1 or 0). It is defined as:\n",
    "\n",
    "\n",
    "Population Brier Score:\n",
    "\n",
    "$B_p =\\mathbb{E} ( (Y - X)^2)$\n",
    "\n",
    "Sample Brier Score:\n",
    "\n",
    "$B_s = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - x_i)^2$\n",
    "\n",
    "Where,\n",
    "\n",
    "- $ N $ is the number of predictions\n",
    "- $ x_i $ is the predicted probability for the i-th instance\n",
    "- $ y_i $ is the actual outcome for the $i^{th}$ instance (1 if the answer was correct, 0 if it was not)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc1e6c-3ac9-43de-941d-44c171764c28",
   "metadata": {},
   "source": [
    "##### Example of a Brier Score:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc38d3-de6d-44a1-a9cc-0928f928b024",
   "metadata": {},
   "source": [
    "Lets say we are given this dataset:\n",
    "\n",
    "| Question    | Score | Confidence  |\n",
    "| -------- | ------- | ------- |\n",
    "| 1  | 1 | 90%    |\n",
    "| 2 | 0 | 50%     |\n",
    "| 3     | 1 |  70%   |\n",
    "\n",
    "\n",
    "Then our values would be:\n",
    "\n",
    "\n",
    "$N = 3$\n",
    "\n",
    "$x_1 = 0.9$ <BR>\n",
    "$x_2 = 0.5$ <BR>\n",
    "$x_3 = 0.7$<BR>\n",
    "\n",
    "$y_1 = 1$ <BR>\n",
    "$y_2 = 0$ <BR>\n",
    "$y_3 = 1$<BR>\n",
    "\n",
    "\n",
    "\n",
    "Then our sample Briar Score would be:\n",
    "\n",
    "$B_s = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - x_i)^2 $<BR><BR>\n",
    "$= \\frac{(1 - 0.9)^2 + (0 - 0.5)^2 + (1 - 0.7)^2}{3} $<BR><BR>\n",
    "$= \\frac{(-0.1)^2 + (-0.5)^2 + (0.3)^2}{3} $<BR><BR>\n",
    "$= \\frac{ 0.01 + 0.25 + 0.09}{3}$ <BR><BR>\n",
    "$= \\frac{0.3225}{3}$<BR><BR>\n",
    "$= 0.1075$\n",
    "\n",
    "Note that a lower score is better as this is the *error* of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14c095-2e5a-4fc3-a98a-4b073ef05164",
   "metadata": {},
   "source": [
    "### Llama 3:\n",
    "\n",
    "Llama 3 is a Large Language Model trained to simulate conversation between an Assistant and User. We can provide Llama with a system prompt to define it's goals and specify how we want it's output to look like. Following the system prompt, we can provide it with a passage and corresponding question from our BoolQ dataset. \n",
    "\n",
    "*Example System Prompt with special tokens included: (From Meta)*\n",
    "\n",
    "><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    ">\n",
    ">You are a helpful AI assistant for travel tips and recommendations<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    ">\n",
    ">What can you help me with?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbe4152-9e72-4177-aff9-bcd2c7e673e4",
   "metadata": {},
   "source": [
    "##### Note: The odd formating is how we communicate directions to the model. See explanation below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc6a80b-e8c6-4006-ab57-7603b7c08fc0",
   "metadata": {},
   "source": [
    "\n",
    ">**<|begin_of_text|>:** Specifies the start of the prompt <br>\n",
    ">\n",
    ">**<|start_header_id|>system<|end_header_id|>:** Specifies the role for the following message, i.e. “system”<br>\n",
    ">\n",
    ">**You are a helpful AI assistant for travel tips and recommendations:** The system prompt<br>\n",
    ">\n",
    ">**<|eot_id|>:** Specifies the end of the input message<br>\n",
    ">\n",
    ">**<|start_header_id|>user<|end_header_id|>:** Specifies the role for the following message i.e. “user”<br>\n",
    ">\n",
    ">**What can you help me with?:** The user message<br>\n",
    ">\n",
    ">**<|start_header_id|>assistant<|end_header_id|>:** Ends with the assistant header, to prompt the model to start generation.<br>\n",
    "\n",
    "More documentation on this can be found here : https://llama.meta.com/docs/model-cards-and-prompt-formats/meta-llama-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d887d2-6473-41ed-9736-e553d8fd6e42",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d2a95-b892-4049-a074-aeab9257e753",
   "metadata": {},
   "source": [
    "#### Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4c5e9-86fd-4c78-ae07-4cc5e3287b47",
   "metadata": {},
   "source": [
    "Throughout this project, we attmpted both probabilistic confidence scores as well as stated confidence scores. We based both of these methods off of prior conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42177c8-e0d1-4a4a-9bd1-f1c8b246b5a0",
   "metadata": {},
   "source": [
    "##### Probabilistic Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7d95ea-7473-455b-a230-a9d3938777ec",
   "metadata": {},
   "source": [
    "We based the probabilistic confidence score off of the same logic as the Probability of Precipitation (PoP) used by the National Weather Service. This is a probability where a given score indicates the liklihood that something will happen. In our case, our model should be correct 80% of the times it states it is 80% confident if it is perfectly calibrated.\n",
    "\n",
    "An example output would look like:<BR>\n",
    "**Assistant: Yes, 90%**\n",
    "\n",
    "More info on PoP:<br>\n",
    "https://www.weather.gov/media/pah/WeatherEducation/pop.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7d86c-297c-4a7f-9863-a83dea5b7503",
   "metadata": {},
   "source": [
    "##### Stated Confidence Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b88dc7-29ea-49df-8310-dfcdbfad5d1c",
   "metadata": {},
   "source": [
    "Later in our research, we wanted to see if a stated confidence score would lead to better results. The motivation behind this was that the model may naturally have a better understanding of a stated word over a numerical score. We borrowed the idea of Words of Estimative Probabilities or WEPs from the intelligence community. We used several different phrases to represent different confidence levels:\n",
    "\n",
    "\n",
    "| Very Uncertain | Somewhat Uncertain | Moderately Certain | Fairly Certain | Very Certain |\n",
    "|-|-|-|-|-|\n",
    "| 50% | 60% | 70% | 80% | 90% |\n",
    "\n",
    "\n",
    "\n",
    "For more documentation on the CIA's Words of Estimative Probabilities, see:\n",
    "https://www.cia.gov/resources/csi/static/Words-of-Estimative-Probability.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49038886-562d-45b5-b94a-c4c8e8b42af5",
   "metadata": {},
   "source": [
    "#### Logit-Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c789d3a-5dc2-44c7-b5d5-aebd6cbe69ea",
   "metadata": {},
   "source": [
    "When the model is given an input, it runs that input through several layers and outputs a list of *logits*. These are unormallized outputs assigned to each *token*. We then can run these logits through the *softmax* function to normalize these logit scores into a probability from 0-100% with the sum of all ptobabilities equalling 100%. These probabalities are based on how likely the model believes the token is to be the next word. \n",
    "\n",
    "For Example, a model may only have three tokens: \"Yes\", \"No\", and \"Maybe\". Then a conversation may look like this:\n",
    "\n",
    "**User**: Does it tend to rain in the fall?\n",
    "\n",
    "Based on this question, the model may create this table of values:\n",
    "\n",
    "| Token | Logit | Probability |\n",
    "|-------|-------|-------------|\n",
    "| Yes   | 8 | 87.6% |\n",
    "| Maybe | 6 | 11.8% |\n",
    "| No | 3 | 0.6% |\n",
    "\n",
    "As \"Yes\" is the token with the highest probability, the model would output:\n",
    "\n",
    "**Assistant**: Yes\n",
    "\n",
    "This table is usually not shown to the user however in our case it was useful to examine. Although inherently different from the confidence score discussed earlier, these \"Logit-Probability\" scores can give us insight into the models thinking. Because of this it is helpful to also examine these scores. In our data collection, we chose to omit the Logit scores and only show the normalized probability as they were not pertinent to what we were investigating. \n",
    "\n",
    "To get a value for a probability score for a given output we take the probability of the answered token and divide it by the sum of the probabilities of the 'Yes' and 'No' tokens. \n",
    "\n",
    "In our example:<BR><BR>\n",
    "<span style=\"font-size: 1.25em;\">\n",
    "$P_{answer} = \\frac{P_{yes}}{P_{yes} + P_{no}} $ <BR><BR>\n",
    "$= \\frac{0.876}{0.876 + 0.006}$ <BR><BR>\n",
    "$= \\frac{0.876}{0.882} = 0.993$ <BR>\n",
    "\n",
    "\n",
    "See below for a more in depth explanation of *Tokens* and  the *Softmax Function*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34394234-c829-469b-9b5c-ad8f93eeea65",
   "metadata": {},
   "source": [
    "#### Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316695b2-4490-41cd-a441-d55780bf4268",
   "metadata": {},
   "source": [
    "Chain of Thought (CoT) prompting is a technique used to improve the reasoning and output quality of Large Language Models (LLMs) like GPT-3, GPT-4, and others. The idea is to prompt the model to \"think\" through a problem step-by-step, just like a human would. By breaking down the problem into smaller parts and solving each part sequentially, the model can provide more accurate and coherent responses. By using CoT, we can also gain insight into *how* the model got to its conclusion instead of the answer by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d70a99-5350-4916-a30e-c5de8c872204",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc212c-654e-47a2-b059-b01f17f4c106",
   "metadata": {},
   "source": [
    "Tokens are words or word fragments that the model has been pretrained to have embeddings for. These embeddings are high-dimensional vectors that help the model gain a sense of word association.\n",
    "\n",
    "Example:\n",
    "\n",
    "\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration.\"<BR>\n",
    "-(Attention Is All You Need, Vaswani et al.)<BR>\n",
    "https://arxiv.org/abs/1706.03762\n",
    "\n",
    "Tokenization:\n",
    "\n",
    "<span style=\"color: red; font-size: 1.5em;\"> The <span style=\"color: blue;\"> dom<span style=\"color: green;\">inant <span style=\"color: orange;\">seq<span style=\"color: blue;\">uence <span style=\"color: red;\">trans<span style=\"color: purple;\">duc<span style=\"color: orange;\">tion <span style=\"color: blue;\">model<span style=\"color: orange;\">s <span style=\"color: green;\">are <span style=\"color: red;\">base<span style=\"color: blue;\">d <span style=\"color: orange;\">on <span style=\"color: black;\">...\n",
    "\n",
    "Notice how at times the token includes the entire word and at times it is only a word fragment. Different models and tokenizers can be trained to split words differently with some tokenizers even assigning multiple words to one token.\n",
    "\n",
    "\n",
    "For more see Grant Sanderson's video on this:\n",
    "\n",
    "https://youtu.be/wjZofJX0v4M?si=HeZizJeOrIBvCPko&t=748\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def63ea1-d6e2-41b9-b558-200d3698242f",
   "metadata": {},
   "source": [
    "##### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d417644-547c-497d-910c-2d7abd47d246",
   "metadata": {},
   "source": [
    "The Softmax function is defined as:<BR>\n",
    "<span style=\"font-size: 2em;\">\n",
    "$\\sigma (z_i) = \\frac{  e^{z_i} }{\\sum_{j=1}^n e^{z_j}}$<BR>\n",
    "<span style=\"font-size: 0.5em;\">\n",
    "Given logit vector $z = [8, 6, 3] $ from our example:<BR>\n",
    "<span style=\"font-size: 1.5em;\">\n",
    "$\\sum_{j=1}^n e^{z_j} = e^8 + e^6 + e^3 = 3404$<BR>\n",
    "\n",
    "Thus,<BR>\n",
    "<span style=\"font-size: 1.5em;\">\n",
    "$\\sigma (z_1) = \\sigma (8) = \\frac{  e^{8} }{\\sum_{j=1}^n e^{z_j}} = \\frac{2980}{3404} = 0.875$<BR><BR>\n",
    "<span style=\"font-size: 1em;\">\n",
    "$\\sigma (z_2) = \\sigma (6) =\\frac{  e^{6} }{\\sum_{j=1}^n e^{z_j}} = \\frac{403}{3404} = 0.118$<BR><BR>\n",
    "<span style=\"font-size: 1em;\">\n",
    "$\\sigma (z_3) = \\sigma (3) =\\frac{  e^{3} }{\\sum_{j=1}^n e^{z_j}} = \\frac{20}{3404} = 0.006$<BR><BR>\n",
    "\n",
    "\n",
    "For simplicity, we rounded to whole numbers in the intermediate step.\n",
    "\n",
    "For more see Grant Sanderson's video on this and how *temperature* can impact output:\n",
    "\n",
    "https://youtu.be/wjZofJX0v4M?si=8Ex7TbUwsJBtVIrG&t=1342"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24708d67-0b20-407e-83a7-90edf30cc479",
   "metadata": {},
   "source": [
    "# Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09116ee0-f05e-4baa-97ff-6bd7c9d0272e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57505eca-5b8d-433c-8638-a061fca3a81f",
   "metadata": {},
   "source": [
    "We wanted to see how accurate these confidence scores were. To do this, we plotted the confidence levels against the average score of the given interval. We compared that to the 45 degree line which represents a perfectly calibrated result. We also plotted a histogram of the distribution of the given confidence level. We did the same with the Logit-Probability Scores to better understand the behavior of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef996e7-2ee3-46b3-aaa0-603b0d1ed4f3",
   "metadata": {},
   "source": [
    "### Original Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8698c08-5143-40e6-94b9-7a6209fb4414",
   "metadata": {},
   "source": [
    "Stated Confidence            |  Logit-Probability\n",
    ":-------------------------:|:-------------------------:\n",
    "![logo](Results/V1/StatedConfidenceVSProportionCorrectV1.png) |  ![logo](Results/V1/LogitProbabilityVSProportionCorrectV1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd4b4f-2694-41a0-a76b-769823a2921b",
   "metadata": {},
   "source": [
    "We eventually were able to improve on these results by using several techniques. By combining the use of n-shot and Chain of Thought prompting as well as using WEPs we were able to greatly reduce the Brier Score of the Stated Confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f712a3-cff5-43ee-bc51-401d8690a97a",
   "metadata": {},
   "source": [
    "### Final Version:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211e676-8c42-452a-ba8a-a4e028a44a08",
   "metadata": {},
   "source": [
    "Stated Confidence            |  Logit-Probability\n",
    ":-------------------------:|:-------------------------:\n",
    "![logo](Results/V6/StatedConfidenceVSProportionCorrectV6.png) |  ![logo](Results/V6/LogitProbabilityVSProportionCorrectV6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6172e15-2f6f-4678-b9ca-832cebd350c2",
   "metadata": {},
   "source": [
    "We also compared the Brier scores across our versions. For each version, we included the Brier Score of the Stated Confidence and the Logit-Probability. In later versions, we used techniques that were more computationally intensive so we decreased the sample size. This led to larger confidence intervals as seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5972a0-1518-4fe9-be71-6805565dced2",
   "metadata": {},
   "source": [
    "### Brier Scores Across Versions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939967fa-096a-41d9-98ae-5c200ea03975",
   "metadata": {},
   "source": [
    "![img](Results/BS_All.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527aad0-c0c2-4093-b02c-48f459f1c11f",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffd05b7-ddb9-4266-8c19-7e5ffaba41bf",
   "metadata": {},
   "source": [
    "## Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd3861-6c47-4ffc-be25-815c28940246",
   "metadata": {},
   "source": [
    " Analyzing our results, we found that the model tended to be overconfident. Whether it was through probabilistic or stated confidence scores, the model always tended to prefer the strongest score whether or not it was appropriate. However, its logit-probability scores tended to have a lower standard deviation. Comparing the Brier scores across our versions, we found that the WEP technique used in versions 5 and 6 had the best results. The reason for the logit probability staying mostly even is that our prompting mostly focused on the stated confidence score, not the underlying weights that impact logit scores. We were able to see significant improvements with Version 6’s Brier Score being 46% lower than our original version. Version 5 and 6 used both WEP confidence scores and Chain of Thought (CoT) prompting. CoT requires the model to give reasoning before it provides an answer which we believe leads to better calibration. Versions 5 and 6 also provided the model with examples of what a conversation should look like. This helped the model format better responses. In our testing, we found that including WEPs with only positive sentiment caused the model to be drastically biased towards answering “Yes” to each question. This suggests that the model is very sensitive to the specific phrases used to measure confidence. The shift to using CoT before the output rather than after also lead to a noticeable improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57d7ae-cfe6-40f9-81c3-86e329d05c17",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08094bcf-f253-4a2c-a1ce-5754ae6bd013",
   "metadata": {},
   "source": [
    "Seeing how sensitive the model was to the format and phrasing of the WEP we would like to investigate this method further. There are multiple different scales used worldwide by various organizations to measure confidence. Ideally, we would want a scale that is as neutral as possible in sentiment so as to not bias the model. Additionally, we would like to use Retrieval-Augmented Generation (RAG) to improve the model's reasoning skills. RAG involves connecting the model to a large database like Wikipedia and having it find the answer on its own. Currently, BoolQ provides the answer in the passage. By using RAG, we hope to see how the model behaves with more open-ended questions. Furthermore, While working on this project, we stuck to Llama 3-8b. We chose to use this model with only 8 billion parameters rather than the 70 billion parameter one largely for computational reasons. Even with the 8B model each output took around 30-45 seconds. This led to compute time of several hours to test each version.\n",
    "\n",
    "Recently, Meta has published Llama 3.1 with 8B, 70B, and 405B parameters. It would be interesting to see how this newer, larger model compares to the one we currently are using. To do this, we would want to refine our methodology to lower compute time. Finally, we would like to investigate how fine-tuning the model would impact the calibration. Ideally, we would want the model to output an appropriate confidence level and have that confidence level correspond to its Logit-Probability score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
